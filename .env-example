# Codex Environment Variables - Template
# Copy this file to .env and fill in your values

# OpenAI API Configuration
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL_NAME=gpt-3.5-turbo

# Vector Database Configuration
# ChromaDB will now use SQLite by default instead of duckdb+parquet
PERSIST_DIRECTORY=.codex_data/chroma

# Optional Configuration
# EMBEDDING_MODEL=all-MiniLM-L6-v2  # Default embedding model
# MAX_TOKENS=500  # Maximum tokens for generation
# TEMPERATURE=0.7  # Temperature for generation

# Local models configuration
# Path to local model weights (if using local LLMs)
LOCAL_MODEL_PATH=models/llama-2-7b-chat.Q4_K_M.gguf 

# Avoid tokenizers parallelism warning
TOKENIZERS_PARALLELISM=false 